{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Machine Learning Algorithm - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use a logistic regression which will take the all the columns except the dependent variable and will predict their absenteeism , we expect that half of those predictors won't have merit. \n",
    "\n",
    "### To me it seems that the \"Reason for Absence\" will be the most indicative may be \"Daily Workload Average\" will have something to do with it as well Since the buiser person is , the less he/she will want to skip work.\n",
    "### Finally , \"children\" and \"pets\" together with \"Distance from work\" should also have something to do with absenteeism. If your child or pet is sick at home you'll have to go home take them to the doctor and get them back which will be more time consuming than a simple visit to the doctor.\n",
    "\n",
    "### The nice thing about regression is that the model itself will give us a fair indication of which variables are important for the analysis and which aren't"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = pd.read_csv(\"Absenteeism_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Excessive Absenteeism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>-0.683704</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>0.412816</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>-0.806331</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>-0.683704</td>\n",
       "      <td>-1.574681</td>\n",
       "      <td>-1.141882</td>\n",
       "      <td>2.130803</td>\n",
       "      <td>-0.806331</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.589690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>-0.007725</td>\n",
       "      <td>-0.654143</td>\n",
       "      <td>1.426749</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>-0.806331</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.919030</td>\n",
       "      <td>-0.589690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>0.668253</td>\n",
       "      <td>0.854936</td>\n",
       "      <td>-1.682647</td>\n",
       "      <td>0.405184</td>\n",
       "      <td>-0.806331</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>-0.589690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>0.668253</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>0.412816</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>-0.806331</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  Day of the Week  \\\n",
       "0         0         0         0         1     0.182726        -0.683704   \n",
       "1         0         0         0         0     0.182726        -0.683704   \n",
       "2         0         0         0         1     0.182726        -0.007725   \n",
       "3         1         0         0         0     0.182726         0.668253   \n",
       "4         0         0         0         1     0.182726         0.668253   \n",
       "\n",
       "   Transportation Expense  Distance to Work       Age  \\\n",
       "0                1.005844          0.412816 -0.536062   \n",
       "1               -1.574681         -1.141882  2.130803   \n",
       "2               -0.654143          1.426749  0.248310   \n",
       "3                0.854936         -1.682647  0.405184   \n",
       "4                1.005844          0.412816 -0.536062   \n",
       "\n",
       "   Daily Work Load Average  Body Mass Index  Education  Children      Pets  \\\n",
       "0                -0.806331         0.767431          0  0.880469  0.268487   \n",
       "1                -0.806331         1.002633          0 -0.019280 -0.589690   \n",
       "2                -0.806331         1.002633          0 -0.919030 -0.589690   \n",
       "3                -0.806331        -0.643782          0  0.880469 -0.589690   \n",
       "4                -0.806331         0.767431          0  0.880469  0.268487   \n",
       "\n",
       "   Excessive Absenteeism  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward elimination we remove the features who have no contribution in our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed.drop(['Daily Work Load Average','Distance to Work','Day of the Week'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use Logistic Regression to predict absenteeism.\n",
    "\n",
    "### Logistic Regression is type of classification so we will basically classifying people into classes \n",
    "\n",
    "### What are these classes ?\n",
    "\n",
    "### We have already created classes from \"Absenteeism in hours\" column in our preprocessing part and we have class like :\n",
    "\n",
    "### 1. Representing people who have been excessively absent.\n",
    "\n",
    "### 2. Representing people who haven't means moderately absent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting / Overfitting \n",
    "\n",
    "### The two concepts that are interrelated underfitting and overfitting goes together.\n",
    "\n",
    "### ----> Overfitting :\n",
    "### Overfitting means our regression has focused on the particular dataset so much it has missed the point.\n",
    "\n",
    "### ----> Underfitting :\n",
    "### Underfitting means the model has not captured the underlying logic of the data\n",
    "\n",
    "### Solution :\n",
    "### We can split our initial dataset into two traning and testing split like 70/30\n",
    "\n",
    "### We create the regression on the traning data , after we have coefficient we test the model on the test data by assessing the accuracy.\n",
    "\n",
    "### The whole point is that the model has never seen the test dataset. So , there's no overfitting and we have Good Model.\n",
    "\n",
    "### ---> Good Model :\n",
    "### Capture the underlying logic of the dataset. High train accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test and shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = data_preprocessed.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Age</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>-1.574681</td>\n",
       "      <td>2.130803</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>-0.654143</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.919030</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>0.854936</td>\n",
       "      <td>0.405184</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  \\\n",
       "0         0         0         0         1     0.182726   \n",
       "1         0         0         0         0     0.182726   \n",
       "2         0         0         0         1     0.182726   \n",
       "3         1         0         0         0     0.182726   \n",
       "4         0         0         0         1     0.182726   \n",
       "\n",
       "   Transportation Expense       Age  Body Mass Index  Education  Children  \\\n",
       "0                1.005844 -0.536062         0.767431          0  0.880469   \n",
       "1               -1.574681  2.130803         1.002633          0 -0.019280   \n",
       "2               -0.654143  0.248310         1.002633          0 -0.919030   \n",
       "3                0.854936  0.405184        -0.643782          0  0.880469   \n",
       "4                1.005844 -0.536062         0.767431          0  0.880469   \n",
       "\n",
       "       Pets  \n",
       "0  0.268487  \n",
       "1 -0.589690  \n",
       "2 -0.589690  \n",
       "3 -0.589690  \n",
       "4  0.268487  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = data_preprocessed[\"Excessive Absenteeism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "695    1\n",
       "696    0\n",
       "697    1\n",
       "698    0\n",
       "699    0\n",
       "Name: Excessive Absenteeism, Length: 700, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By splitting the scaled_inputs and targets we are getting Four Arrays :\n",
    "\n",
    "### Array 1 : A training dataset with inputs \n",
    "### Array 2 : A training dataset with targets\n",
    "\n",
    "### Array 3 : A test dataset with inputs\n",
    "### Array 4 : A test dataset with targets \n",
    "\n",
    "### Obviously this output is of no use until we declare Four Variable that will contain the four outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     Reason_1  Reason_2  Reason_3  Reason_4  Month Value  \\\n",
       " 238         1         0         0         0     0.182726   \n",
       " 253         0         0         1         0     0.468236   \n",
       " 16          0         0         0         1     0.182726   \n",
       " 280         0         0         0         1     0.753746   \n",
       " 671         0         0         1         0    -0.673803   \n",
       " ..        ...       ...       ...       ...          ...   \n",
       " 64          0         0         0         0     1.039256   \n",
       " 301         0         0         1         0     1.039256   \n",
       " 176         1         0         0         0    -0.959313   \n",
       " 358         0         0         0         1    -1.530333   \n",
       " 27          0         0         0         1     0.468236   \n",
       " \n",
       "      Transportation Expense       Age  Body Mass Index  Education  Children  \\\n",
       " 238               -1.574681  0.091435         0.297027          0 -0.919030   \n",
       " 253               -0.986140 -1.163560        -1.114186          0 -0.919030   \n",
       " 16                -0.654143  0.248310         1.002633          0 -0.919030   \n",
       " 280               -0.654143  0.248310         1.002633          0 -0.919030   \n",
       " 671                0.040034 -1.320435        -0.643782          0 -0.019280   \n",
       " ..                      ...       ...              ...        ...       ...   \n",
       " 64                -1.574681  2.130803         1.002633          0 -0.019280   \n",
       " 301                1.005844 -0.536062         0.767431          0  0.880469   \n",
       " 176               -0.654143 -1.006686        -1.819793          1 -0.919030   \n",
       " 358                0.040034 -1.320435        -0.643782          0 -0.019280   \n",
       " 27                -0.986140 -1.163560        -1.114186          0 -0.919030   \n",
       " \n",
       "          Pets  \n",
       " 238 -0.589690  \n",
       " 253 -0.589690  \n",
       " 16  -0.589690  \n",
       " 280 -0.589690  \n",
       " 671  1.126663  \n",
       " ..        ...  \n",
       " 64  -0.589690  \n",
       " 301  0.268487  \n",
       " 176 -0.589690  \n",
       " 358  1.126663  \n",
       " 27  -0.589690  \n",
       " \n",
       " [525 rows x 11 columns],\n",
       "      Reason_1  Reason_2  Reason_3  Reason_4  Month Value  \\\n",
       " 612         0         0         0         1    -1.244823   \n",
       " 272         0         0         1         0     0.753746   \n",
       " 134         0         0         0         1    -1.530333   \n",
       " 538         1         0         0         0     1.324766   \n",
       " 80          0         0         0         1     1.324766   \n",
       " ..        ...       ...       ...       ...          ...   \n",
       " 371         1         0         0         0    -1.244823   \n",
       " 95          0         0         0         1     1.324766   \n",
       " 222         1         0         0         0    -0.102784   \n",
       " 562         0         0         1         0     1.610276   \n",
       " 220         0         0         1         0    -0.102784   \n",
       " \n",
       "      Transportation Expense       Age  Body Mass Index  Education  Children  \\\n",
       " 612               -0.654143  0.248310         1.002633          0 -0.919030   \n",
       " 272                1.005844 -0.536062         0.767431          0  0.880469   \n",
       " 134               -1.574681  0.091435         0.297027          0 -0.919030   \n",
       " 538                0.190942 -0.692937        -0.408580          1 -0.919030   \n",
       " 80                -0.654143  0.248310         1.002633          0 -0.919030   \n",
       " ..                      ...       ...              ...        ...       ...   \n",
       " 371                0.040034 -1.320435        -0.643782          0 -0.019280   \n",
       " 95                 0.040034 -1.320435        -0.643782          0 -0.019280   \n",
       " 222                0.356940  0.718933        -0.878984          0 -0.919030   \n",
       " 562               -0.654143  0.562059        -1.114186          1  0.880469   \n",
       " 220                0.356940  0.718933        -0.878984          0 -0.919030   \n",
       " \n",
       "          Pets  \n",
       " 612 -0.589690  \n",
       " 272  0.268487  \n",
       " 134 -0.589690  \n",
       " 538 -0.589690  \n",
       " 80  -0.589690  \n",
       " ..        ...  \n",
       " 371  1.126663  \n",
       " 95   1.126663  \n",
       " 222 -0.589690  \n",
       " 562 -0.589690  \n",
       " 220 -0.589690  \n",
       " \n",
       " [175 rows x 11 columns],\n",
       " 238    1\n",
       " 253    0\n",
       " 16     0\n",
       " 280    0\n",
       " 671    1\n",
       "       ..\n",
       " 64     0\n",
       " 301    1\n",
       " 176    0\n",
       " 358    1\n",
       " 27     1\n",
       " Name: Excessive Absenteeism, Length: 525, dtype: int64,\n",
       " 612    0\n",
       " 272    1\n",
       " 134    0\n",
       " 538    1\n",
       " 80     0\n",
       "       ..\n",
       " 371    0\n",
       " 95     0\n",
       " 222    1\n",
       " 562    0\n",
       " 220    1\n",
       " Name: Excessive Absenteeism, Length: 175, dtype: int64]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(scaled_inputs,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventinally we provide the name of our Four variable x_train , x_test , y_train , y_test\n",
    "\n",
    "### we have parameter train_size which take values between 0 and 1 , if we take 0.8 means that 80% of our data will be used for training 20 for testing \n",
    "\n",
    "### In train_test_split method we have  shuffle parameter , Shuffle is a Boolean so it can be either true or false by default shuffling is set to true\n",
    "\n",
    "### For shuffling parameter by default true may be a small issue for us , When we rerun a code we get a different split every time. This causes the final model to differ every time due to the shuffling \n",
    "\n",
    "### We may get LUCKY and achieve higher accuracy because of the split, or get UNLUCKY and achieve lower accuracy , So the shuffle can make things difficult for us.\n",
    "\n",
    "### All Sklearn functions that include some randomness like random shuffle here contain a random state parameter , random_state takes integer values we can set it to 20 it take any value it doesn't matter.\n",
    "\n",
    "### This will make the shuffle pseudo random.\n",
    "\n",
    "### In this way , the method will always shuffle the observations in the same 'random' way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(scaled_inputs,targets,train_size=0.8,random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we check the shapes of our variables\n",
    "\n",
    "### We've got 560 observation for training and 140 observation for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 11) (560,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 11) (140,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning is 90% Preprocessing and 10% Modeling \n",
    "\n",
    "### Finally we reach the heart of the algorithm that is modeling part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Sklearn\n",
    "\n",
    "### Import the relevant libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We must declare a new variable which will be a logistic regression object\n",
    "\n",
    "### Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We must Fit the regression , this method done basically all the machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pradeep Chaudhary\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model accuracy\n",
    "\n",
    "### There are two required argument inputs and targets\n",
    "\n",
    "### We conculde that our model has accuracy approx 78 % \n",
    "\n",
    "### Based on the data we used , our model learned to classify ~78% of the observation correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually check the accuracy\n",
    "\n",
    "### Reason we check accuracy manually \n",
    "\n",
    "### It is always good understanding of what we are doing \n",
    "\n",
    "### What does accuracy mean ?\n",
    "\n",
    "### The logistic regression model is train on the train inputs based on them it finds outputs which are trying to be as close to the targets as possible , However accuracy means that x% of the model outputs match the targets\n",
    "\n",
    "### So , if find the accuracy of a model manually we should find the outputs and compare them with the targets\n",
    "\n",
    "### In order to find model output we use predict method\n",
    "\n",
    "### This method will find the predicted outputs of the regression \n",
    "\n",
    "### These are the prediction of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs = reg.predict(x_train)\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have to display the targets and compare the two\n",
    "\n",
    "### The two array look alike but have many differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346    0\n",
       "91     1\n",
       "299    1\n",
       "129    1\n",
       "695    1\n",
       "      ..\n",
       "218    1\n",
       "223    1\n",
       "271    0\n",
       "474    1\n",
       "355    0\n",
       "Name: Excessive Absenteeism, Length: 560, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have to compare the predicted outputs and the targets \n",
    "\n",
    "### We are getting the array of element , if there's a match we get True and if don't we get False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346     True\n",
       "91      True\n",
       "299     True\n",
       "129     True\n",
       "695     True\n",
       "       ...  \n",
       "218     True\n",
       "223    False\n",
       "271     True\n",
       "474    False\n",
       "355     True\n",
       "Name: Excessive Absenteeism, Length: 560, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs == y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can clearly see which elements have been guessed correctly and which haven't , But how many are there.\n",
    "\n",
    "### We know True is same as 1 , False is same as 0 for boolean \n",
    "\n",
    "### So let's sum this array , The result will be the total number of True entries \n",
    "\n",
    "### If we divide the number of matches by the total number of elements will get the accuracy \n",
    "\n",
    "### Accuracy = Correct prediction / # observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model_outputs == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We get the same result as we are getting from score method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model_outputs == y_train) / model_outputs.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a summary table with the Coefficients and Intercept\n",
    "\n",
    "### Regression analysis no matter if linear or non linear is about determining certain coefficient or weights which we apply to the inputs to obtain the final result\n",
    "\n",
    "### If we use this model outside of python , we must get the coefficient and the intercept , Moreover in order to interpret this logistic model we still need this to do so.\n",
    "\n",
    "### Finding the intercept and coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.46547112])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.62749942,  0.86338637,  2.96050661,  0.66390745,  0.15493732,\n",
       "         0.59979822, -0.17245127,  0.27568526, -0.23452541,  0.34249662,\n",
       "        -0.2775137 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However this result not truly get us where we want to be \n",
    "\n",
    "### We want to know what variable these coefficient refer to \n",
    "\n",
    "### We can get the coefficients from the names of our inputs column values \n",
    "\n",
    "### We have sacles_inputs which contain the inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Month Value',\n",
       "       'Transportation Expense', 'Age', 'Body Mass Index', 'Education',\n",
       "       'Children', 'Pets'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_inputs.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We create a variable that will contain all the information called feature_name\n",
    "\n",
    "### We want a neat dataframe that will contain the intercept , the feature names and the corresponding coefficient we can call this dataframe summary table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = scaled_inputs.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.627499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.863386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Reason_3</td>\n",
       "      <td>2.960507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.663907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.154937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.599798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Age</td>\n",
       "      <td>-0.172451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.275685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Education</td>\n",
       "      <td>-0.234525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Children</td>\n",
       "      <td>0.342497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.277514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature name  Coefficient\n",
       "0                 Reason_1     2.627499\n",
       "1                 Reason_2     0.863386\n",
       "2                 Reason_3     2.960507\n",
       "3                 Reason_4     0.663907\n",
       "4              Month Value     0.154937\n",
       "5   Transportation Expense     0.599798\n",
       "6                      Age    -0.172451\n",
       "7          Body Mass Index     0.275685\n",
       "8                Education    -0.234525\n",
       "9                 Children     0.342497\n",
       "10                    Pets    -0.277514"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table = pd.DataFrame(columns=['Feature name'],data=feature_name)\n",
    "\n",
    "summary_table['Coefficient'] = np.transpose(reg.coef_)\n",
    "\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have nice and clean summary table with all the variables and their corresponding coefficient.\n",
    "\n",
    "### The only thing we are missing is the intercept \n",
    "\n",
    "### There are several way we can add it \n",
    "\n",
    "### Two alternative are using the append or concatenate methods\n",
    "\n",
    "### However most the method will put the newly appendend data at the end of the dataframe , But there is no prepand method\n",
    "\n",
    "### The way we deal this is the following \n",
    "\n",
    "### Add one to all index , In this way we will shift up all indices by 1 \n",
    "\n",
    "### Now the zero index is empty , fill it then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table.index = summary_table.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.465471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.627499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.863386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Reason_3</td>\n",
       "      <td>2.960507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.663907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.154937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.599798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Age</td>\n",
       "      <td>-0.172451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.275685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Education</td>\n",
       "      <td>-0.234525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Children</td>\n",
       "      <td>0.342497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.277514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature name  Coefficient\n",
       "0                Intercept    -1.465471\n",
       "1                 Reason_1     2.627499\n",
       "2                 Reason_2     0.863386\n",
       "3                 Reason_3     2.960507\n",
       "4                 Reason_4     0.663907\n",
       "5              Month Value     0.154937\n",
       "6   Transportation Expense     0.599798\n",
       "7                      Age    -0.172451\n",
       "8          Body Mass Index     0.275685\n",
       "9                Education    -0.234525\n",
       "10                Children     0.342497\n",
       "11                    Pets    -0.277514"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table.loc[0] = ['Intercept',reg.intercept_[0]]\n",
    "summary_table = summary_table.sort_index()\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the coefficient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient also called the weights while the intercept called the bias\n",
    "\n",
    "### These notions are useful because the weights show how we weigh a certain input.\n",
    "\n",
    "### The closer they are to zero the smaller the weight and alternatively the further away from zero no matter if positive or negative , The bigger the weight of this feature.\n",
    "\n",
    "### Note that this is something which is true for our model , but it's not universally be true \n",
    "\n",
    "### It holds only for models where all variables are of the same scale such as the one we just built.\n",
    "\n",
    "### There are coefficient values and standardized coefficient values.\n",
    "\n",
    "### These standardized coefficient are basically :\n",
    "### the coefficient of a regression where all variables have been standardized\n",
    "\n",
    "### Other packages in software include the standardized coefficients because they allow for a simple and easy way to understand comparison between the variables since in such cases the features are standardized.\n",
    "\n",
    "### They all have a variance of 1 or the same scale and , Whenever the scale is standard or the same that is we can simply say whichever way it is bigger its corresponding feature is more important.\n",
    "\n",
    "### For machine learning purposes and prediction in general we usually standardize the variables like we did.\n",
    "\n",
    "### Whenever we are dealing with a logistic regression the coefficients we are predicting are the so called log(odds) , This is the consequence of the choice of model \n",
    "\n",
    "### Logistic Regression Bydefault are nothing but a linear function predicting log(odds) , These log(odds) are later transformed into 0 and 1\n",
    "\n",
    "### Logistic Regression equation :\n",
    "\n",
    "### log(odds) = intercept + b1x1 + b2x2 + ..... + b13x13 + b14x14\n",
    "\n",
    "### -0.21 + 2.07 * Reason_1 + 0.33 * Reason_2 + 1.56 * Reason_3 + 1.31 * Reason_4 + 0.03 * Month + (-0.09) * Day of week + 0.72 * Transport + (-0.06) * Distance + (-0.21) * Age + 0.03 * Daily Workload + 0.33 * Body Mass index + (-0.16) * Education + 0.38 * Children + (-0.32) * Pet\n",
    "\n",
    "### Therefore all the coefficients that we have refered to the log odds.\n",
    "\n",
    "### So , to make them more interpretable , we have to find the exponential of these coefficients\n",
    "\n",
    "### We will create a new series in our data frame called Odds Ratio \n",
    "\n",
    "### Odds Ratio is the correct term for what we will get after we find the exponentials of the coefficient \n",
    "\n",
    "### We added a new column to our  table where we had the exponentials of the coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table['Odds_ratio'] = np.exp(summary_table.Coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.465471</td>\n",
       "      <td>0.230969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.627499</td>\n",
       "      <td>13.839121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.863386</td>\n",
       "      <td>2.371177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Reason_3</td>\n",
       "      <td>2.960507</td>\n",
       "      <td>19.307751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.663907</td>\n",
       "      <td>1.942367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.154937</td>\n",
       "      <td>1.167585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.599798</td>\n",
       "      <td>1.821751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Age</td>\n",
       "      <td>-0.172451</td>\n",
       "      <td>0.841599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.275685</td>\n",
       "      <td>1.317433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Education</td>\n",
       "      <td>-0.234525</td>\n",
       "      <td>0.790946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Children</td>\n",
       "      <td>0.342497</td>\n",
       "      <td>1.408460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.277514</td>\n",
       "      <td>0.757665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature name  Coefficient  Odds_ratio\n",
       "0                Intercept    -1.465471    0.230969\n",
       "1                 Reason_1     2.627499   13.839121\n",
       "2                 Reason_2     0.863386    2.371177\n",
       "3                 Reason_3     2.960507   19.307751\n",
       "4                 Reason_4     0.663907    1.942367\n",
       "5              Month Value     0.154937    1.167585\n",
       "6   Transportation Expense     0.599798    1.821751\n",
       "7                      Age    -0.172451    0.841599\n",
       "8          Body Mass Index     0.275685    1.317433\n",
       "9                Education    -0.234525    0.790946\n",
       "10                Children     0.342497    1.408460\n",
       "11                    Pets    -0.277514    0.757665"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will sort the dataframe using the sort values method \n",
    "\n",
    "### Sort values require us to choose the appropriate column by which we want to sort the whole dataframe \n",
    "\n",
    "### By default the coefficient are sorted in ascending order \n",
    "\n",
    "### In our case the most important ones are at the bottom(biggest weight / odds ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.465471</td>\n",
       "      <td>0.230969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.277514</td>\n",
       "      <td>0.757665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Education</td>\n",
       "      <td>-0.234525</td>\n",
       "      <td>0.790946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Age</td>\n",
       "      <td>-0.172451</td>\n",
       "      <td>0.841599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.154937</td>\n",
       "      <td>1.167585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.275685</td>\n",
       "      <td>1.317433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Children</td>\n",
       "      <td>0.342497</td>\n",
       "      <td>1.408460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.599798</td>\n",
       "      <td>1.821751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.663907</td>\n",
       "      <td>1.942367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.863386</td>\n",
       "      <td>2.371177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.627499</td>\n",
       "      <td>13.839121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Reason_3</td>\n",
       "      <td>2.960507</td>\n",
       "      <td>19.307751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature name  Coefficient  Odds_ratio\n",
       "0                Intercept    -1.465471    0.230969\n",
       "11                    Pets    -0.277514    0.757665\n",
       "9                Education    -0.234525    0.790946\n",
       "7                      Age    -0.172451    0.841599\n",
       "5              Month Value     0.154937    1.167585\n",
       "8          Body Mass Index     0.275685    1.317433\n",
       "10                Children     0.342497    1.408460\n",
       "6   Transportation Expense     0.599798    1.821751\n",
       "4                 Reason_4     0.663907    1.942367\n",
       "2                 Reason_2     0.863386    2.371177\n",
       "1                 Reason_1     2.627499   13.839121\n",
       "3                 Reason_3     2.960507   19.307751"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table.sort_values('Odds_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As this looks something awkward we want most important variable are the top so we add another argument ascending equals False returning the cell give us the desired table all coefficient sorted according to the relevance of the problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Reason_3</td>\n",
       "      <td>2.960507</td>\n",
       "      <td>19.307751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.627499</td>\n",
       "      <td>13.839121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.863386</td>\n",
       "      <td>2.371177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.663907</td>\n",
       "      <td>1.942367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.599798</td>\n",
       "      <td>1.821751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Children</td>\n",
       "      <td>0.342497</td>\n",
       "      <td>1.408460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.275685</td>\n",
       "      <td>1.317433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.154937</td>\n",
       "      <td>1.167585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Age</td>\n",
       "      <td>-0.172451</td>\n",
       "      <td>0.841599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Education</td>\n",
       "      <td>-0.234525</td>\n",
       "      <td>0.790946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.277514</td>\n",
       "      <td>0.757665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.465471</td>\n",
       "      <td>0.230969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature name  Coefficient  Odds_ratio\n",
       "3                 Reason_3     2.960507   19.307751\n",
       "1                 Reason_1     2.627499   13.839121\n",
       "2                 Reason_2     0.863386    2.371177\n",
       "4                 Reason_4     0.663907    1.942367\n",
       "6   Transportation Expense     0.599798    1.821751\n",
       "10                Children     0.342497    1.408460\n",
       "8          Body Mass Index     0.275685    1.317433\n",
       "5              Month Value     0.154937    1.167585\n",
       "7                      Age    -0.172451    0.841599\n",
       "9                Education    -0.234525    0.790946\n",
       "11                    Pets    -0.277514    0.757665\n",
       "0                Intercept    -1.465471    0.230969"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table.sort_values('Odds_ratio',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of columns \n",
    "\n",
    "### if a coefficient is around zero\n",
    "### if it's odd ratio is around one \n",
    "\n",
    "### This means that the  corresponding feature is not particularly important\n",
    "\n",
    "### The reasoning in terms of weights is that : \n",
    "### A weight(coefficient) of zero implies that no matter the feature value , we will multiply it by zero(in the model) , and the whole result will be zero.\n",
    "\n",
    "### The meaning in terms of odd ratio is that :\n",
    "### For one unit change in the standardized feature , the odd increase by a multiple equal to the odd ratio \n",
    "### (1=no change)\n",
    "### So , if the odd ratio is one then the odd don't change at all\n",
    "### For example :\n",
    "\n",
    "### Odds : 5:1 Odds ratio : 2 New Odds(for a unti change) : 10:1\n",
    "### The odd change from 5 to 10 because we multiply them by odd ratio\n",
    "### If odd ratio is one we do not have a change as multiplication with the number one keeps odds same.\n",
    "\n",
    "\n",
    "### This make sense as the odd ratio was one whenever the weight is zero\n",
    "\n",
    "### In our dataset :\n",
    "\n",
    "### The \"Daily Work load Average\" weight is -0.03 so almost zero and it's odd ratio is almost one.\n",
    "### So , this feature is almost useless for our model , with or without the result would be the same \n",
    "\n",
    "### \"Day of the week\" and \"Distance to work\" both have weight almost zero and odd ratio almost one.\n",
    "\n",
    "### To be honest this is the bit surprising to me\n",
    "\n",
    "### To justify my mistaken logic this is the time to know that they may not necessarily be useless.\n",
    "\n",
    "### A more accurate statement is that :\n",
    "### Given all features they seem to be  the one that make no difference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation on the most important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Reason_3</td>\n",
       "      <td>2.960507</td>\n",
       "      <td>19.307751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.627499</td>\n",
       "      <td>13.839121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.863386</td>\n",
       "      <td>2.371177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.663907</td>\n",
       "      <td>1.942367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.599798</td>\n",
       "      <td>1.821751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Children</td>\n",
       "      <td>0.342497</td>\n",
       "      <td>1.408460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.275685</td>\n",
       "      <td>1.317433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.154937</td>\n",
       "      <td>1.167585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Age</td>\n",
       "      <td>-0.172451</td>\n",
       "      <td>0.841599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Education</td>\n",
       "      <td>-0.234525</td>\n",
       "      <td>0.790946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.277514</td>\n",
       "      <td>0.757665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.465471</td>\n",
       "      <td>0.230969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature name  Coefficient  Odds_ratio\n",
       "3                 Reason_3     2.960507   19.307751\n",
       "1                 Reason_1     2.627499   13.839121\n",
       "2                 Reason_2     0.863386    2.371177\n",
       "4                 Reason_4     0.663907    1.942367\n",
       "6   Transportation Expense     0.599798    1.821751\n",
       "10                Children     0.342497    1.408460\n",
       "8          Body Mass Index     0.275685    1.317433\n",
       "5              Month Value     0.154937    1.167585\n",
       "7                      Age    -0.172451    0.841599\n",
       "9                Education    -0.234525    0.790946\n",
       "11                    Pets    -0.277514    0.757665\n",
       "0                Intercept    -1.465471    0.230969"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table.sort_values('Odds_ratio',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Interpretation on the most important features\n",
    "\n",
    "### Note :\n",
    "\n",
    "### The further away from 0 a coefficient is , the bigger its importance \n",
    "\n",
    "### So , by looking at the coefficient table we will notice that most strongly features seem to be \"Four Reason for Absence\" , \"The Transportation expense\", and whether a person has \"Children\" , \"Pets\" , and \"Education\".\n",
    "\n",
    "### Note that \"Pets\" and \"Education\" are at the bottom of the table but their weights are still far away from zero. They are indeed important \n",
    "\n",
    "### \"Daily work Load Average\" , \"Distance to Work\" , and \"Day of the week\" , \"Month values\" would seem to have the smallest impact their weight is almost zero so regardless of the particular values they will barely effect our model.\n",
    "\n",
    "### The base model include \"No Reason\" it means when we were creating the dummies the one we dropped was \"Reason_0\" which represented a situation , When a person was absent but no particular reason was given.\n",
    "\n",
    "### Therefore , the base model is the case when there is \"no reason\"\n",
    "\n",
    "### From the coefficient it seem that whenever a person has stated any reason we have a much higher chance of getting excessive absent\n",
    "\n",
    "## Interpretation of the various \"reason for absence\" : \n",
    "\n",
    "### Reason_0 = No reason = basline model (when no reason is given)\n",
    "### Reason_1 which comprises various diseases\n",
    "### Reason_2 relating to pregnancy and giving birth \n",
    "### Reason_3 regarding poisioning and peculiar reason not categorized elsewhere\n",
    "### Reason_4 which related to light diseases \n",
    "\n",
    "## \"Reason_3\" :\n",
    "\n",
    "### On the basis of coefficient and odd ratio the most curical reason for excessive absence is \"Reason_3\" which is poisoning not much of a surprise there , if someone is poisoned they just don't go to work. \n",
    "### The weight means the odds of someone being excessively absent after being poisoned are 20 times higher than when no reason was reported.\n",
    "\n",
    "\n",
    "## \"Reason_1\" :\n",
    "\n",
    "### Another very important reason seem to be number of various diseases \"Reason_1\" . we had to call this the normal absenteeism case if someone got sick they skiped work\n",
    "### A person who has reported this is 14 times more likely to be excessive absent than a person who didn't specify any reason.\n",
    "\n",
    "\n",
    "## \"Reason_2\" :\n",
    "\n",
    "### \"Reason_2\" is for pregnancy and giving birth , I particularly like this feature , because it is a prominent cause of absenteeism , But at the same time is way less pronounce than reason 1 and reason 3. \n",
    "### Explanation for this is a women is pregnant she goes to the gynecologist gets a regular pregnancy check and comes back to work , Nothing excessive about that from time to time but there are some emergencies and the odds ratio we can verify that it's only around 2 times more likely to be excessive absent than the base model.\n",
    "\n",
    "\n",
    "## \"Reason_4\" :\n",
    "\n",
    "### \"Reason_4\" represent the light diseases , this is also the valid for someone absent from work if some got appointment to doctor and if some has fever and they got dentist appoinement then she/he go to docter check and comes back to work , and there is nothing so much excessive unlike some emergenices the odd ratio we see that a person who have light diseases have around 2 times more likely to be excessive absent than a person who didn't specify any reason.\n",
    "\n",
    "\n",
    "## \"Transportation Expense\" :\n",
    "\n",
    "### This is the most important non-dummy feature in the model , but the problem is that it is one of our standardized variables , we don't have direct interpretability of it's odd ratio imples that for 1 standardized unit or for 1 standard deviation increase in transport expense it is close to twice as likely to be excessively absent .\n",
    "\n",
    "### This is the main drawback of standardization , Standardized model almost always yield higher accuracy because the optimization algorithm work better in this way \n",
    "\n",
    "### Machine Learning Engg. :\n",
    "### perfers model with higher accuracy , so they normally go for standardization \n",
    "\n",
    "### Econometricians and Statisticians :\n",
    "### prefer less accurate but more interpretable models , because they care about the underlying reasons behind different phenomena.\n",
    "\n",
    "### Data Scientists :\n",
    "### may be in either position , sometimes they need higher accuracy , other times they find the main drivers problem.\n",
    "\n",
    "\n",
    "### So it make sense to create two different models one with standardized features and one without them and then draw insights from both of them.\n",
    "\n",
    "\n",
    "### However should we option for predicting values we definately prefer higher accuracy , So standardization is more often the norm.\n",
    "\n",
    "\n",
    "### We are going to do this as Data Scientists prespective rather than pure Machine Learning programmer and Statistician , so we can see both side. \n",
    "\n",
    "\n",
    "## \"Children\" : \n",
    "\n",
    "\n",
    "### This is also the most important non-dummy feature in the model , it repersents categorical data containing integers. The  odd ratio imples that for 1 standardized unit or for 1 standard deviation increase in Children it is close to twice as likely to be excessively absent. \n",
    "\n",
    "###  if an individual has children it might be the case if their children were sick at home so employees chances to absent from work to check them up and back to work.\n",
    "\n",
    "\n",
    "## \"Pets\" :\n",
    "\n",
    "\n",
    "### This is negative coefficient and non-dummy feature and a continous variable , it's odd is 0.7 , So for each additional standardized unit of pet ,  The odds are 1-0.759676 = 24% lower than the base model (no pet)\n",
    "\n",
    "### if someone have several pets we're probably not taking care of them on your own not being solely responsible for them implies somebody else can take them to the doctor if something is wrong \n",
    "\n",
    "\n",
    "## \"Education\" :\n",
    "\n",
    "### This is negative coefficient and dummy feature , it's odd is 0.74 it means that if an individual pursue for higher education they might go to the class not in weekdays but in off days but it might be the case if they having test or something so their chance of excessive absent compare who don't pursue higher education and who have higher education is 0.74 times cause that's the odd ratio.\n",
    "\n",
    "\n",
    "## Intercept :\n",
    "\n",
    "### It is used to get more accurate predictions but there's no specific meaning attached to it , That's why in machine learning we can say that it 'calibrates' the model and we can also called it BIAS.\n",
    "\n",
    "### Neverthless without an intercept each prediction would be off the mark by precisely that value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Elimination\n",
    "\n",
    "### The idea is that we can simplify our model by removing all features which have close to no contribution to the model \n",
    "\n",
    "### When we have the p-values , we get rid of all coefficient with p-values > 0.05\n",
    "\n",
    "### But in SKlearn we don't have p-value because we don't necessarily need them because if the weight is small enough it will , it won't make difference anyways \n",
    "\n",
    "### If we remove these variables, the rest of our model should not really change in terms of coefficient values.\n",
    "\n",
    "### We analysis only the most siginificant features , In our model we notice that \"Daily work load average\" , \"Distance to work\" , \"Day of the week\" seemed to have the lowest impact \n",
    "\n",
    "### If we can even call their contribution and impact as their weights are almost zero \n",
    "\n",
    "### NOTE : Month value is useful even if it does not add any predictive power\n",
    "\n",
    "### Checking the regression accuracy we see a slight difference , Moreover we can notice the number of correctly predicted instances\n",
    "\n",
    "### This show us that the 3 variables we dropped were useless , With or Without them we obtain the same results\n",
    "\n",
    "### Either way a simpler model is always preferable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model \n",
    "\n",
    "### Until now whenever we talk about accuracy it is train accuracy at this stage our train accuracy is around 77%\n",
    "\n",
    "### Our algorithm has seen this train data many times in fact thousand of times during  the traning process , so it has learned to model quite well \n",
    "\n",
    "### However it fail miserably when provide the new data as we should test it on data it has never seen.\n",
    "\n",
    "### It is the time when we use test data \n",
    "\n",
    "### Assess the test accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So based on the data that the model has never seen before we can say that  in 75% of the cases of the model will predicted correctly , if a person is going to be excessively absent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the predicted probabilities of each class\n",
    "\n",
    "### the first column shows the probability of a particular observation to be 0(moderate absent), while the second one to be 1(excessively absent)\n",
    "\n",
    "### The summing of any two number horizontally will give an output 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71221976, 0.28778024],\n",
       "       [0.58760009, 0.41239991],\n",
       "       [0.44337438, 0.55662562],\n",
       "       [0.77903962, 0.22096038],\n",
       "       [0.08458343, 0.91541657],\n",
       "       [0.33103371, 0.66896629],\n",
       "       [0.29792496, 0.70207504],\n",
       "       [0.12956221, 0.87043779],\n",
       "       [0.78307821, 0.21692179],\n",
       "       [0.74708659, 0.25291341],\n",
       "       [0.49514969, 0.50485031],\n",
       "       [0.22640297, 0.77359703],\n",
       "       [0.07030984, 0.92969016],\n",
       "       [0.73504052, 0.26495948],\n",
       "       [0.30533085, 0.69466915],\n",
       "       [0.55035881, 0.44964119],\n",
       "       [0.55027426, 0.44972574],\n",
       "       [0.53930442, 0.46069558],\n",
       "       [0.40117774, 0.59882226],\n",
       "       [0.05320682, 0.94679318],\n",
       "       [0.69874615, 0.30125385],\n",
       "       [0.77903962, 0.22096038],\n",
       "       [0.41634563, 0.58365437],\n",
       "       [0.41634563, 0.58365437],\n",
       "       [0.2412915 , 0.7587085 ],\n",
       "       [0.74317087, 0.25682913],\n",
       "       [0.51065194, 0.48934806],\n",
       "       [0.85703303, 0.14296697],\n",
       "       [0.19934235, 0.80065765],\n",
       "       [0.77903962, 0.22096038],\n",
       "       [0.62971577, 0.37028423],\n",
       "       [0.31683213, 0.68316787],\n",
       "       [0.31174245, 0.68825755],\n",
       "       [0.47305759, 0.52694241],\n",
       "       [0.77903962, 0.22096038],\n",
       "       [0.46507358, 0.53492642],\n",
       "       [0.77546993, 0.22453007],\n",
       "       [0.25610763, 0.74389237],\n",
       "       [0.59670727, 0.40329273],\n",
       "       [0.39698373, 0.60301627],\n",
       "       [0.78656024, 0.21343976],\n",
       "       [0.54516654, 0.45483346],\n",
       "       [0.7596912 , 0.2403088 ],\n",
       "       [0.5611569 , 0.4388431 ],\n",
       "       [0.17377065, 0.82622935],\n",
       "       [0.42142868, 0.57857132],\n",
       "       [0.30538941, 0.69461059],\n",
       "       [0.71221976, 0.28778024],\n",
       "       [0.77790972, 0.22209028],\n",
       "       [0.7938926 , 0.2061074 ],\n",
       "       [0.42422877, 0.57577123],\n",
       "       [0.63561337, 0.36438663],\n",
       "       [0.33103371, 0.66896629],\n",
       "       [0.72871439, 0.27128561],\n",
       "       [0.16665264, 0.83334736],\n",
       "       [0.56600768, 0.43399232],\n",
       "       [0.11399337, 0.88600663],\n",
       "       [0.76603645, 0.23396355],\n",
       "       [0.62829315, 0.37170685],\n",
       "       [0.61790495, 0.38209505],\n",
       "       [0.30203861, 0.69796139],\n",
       "       [0.34090197, 0.65909803],\n",
       "       [0.70607803, 0.29392197],\n",
       "       [0.20313854, 0.79686146],\n",
       "       [0.79043907, 0.20956093],\n",
       "       [0.7300077 , 0.2699923 ],\n",
       "       [0.89600113, 0.10399887],\n",
       "       [0.77546993, 0.22453007],\n",
       "       [0.26055756, 0.73944244],\n",
       "       [0.69918168, 0.30081832],\n",
       "       [0.77546993, 0.22453007],\n",
       "       [0.67311234, 0.32688766],\n",
       "       [0.09662446, 0.90337554],\n",
       "       [0.54254271, 0.45745729],\n",
       "       [0.40002753, 0.59997247],\n",
       "       [0.77903962, 0.22096038],\n",
       "       [0.22136985, 0.77863015],\n",
       "       [0.27141023, 0.72858977],\n",
       "       [0.25655446, 0.74344554],\n",
       "       [0.32955172, 0.67044828],\n",
       "       [0.75152292, 0.24847708],\n",
       "       [0.91016537, 0.08983463],\n",
       "       [0.76603645, 0.23396355],\n",
       "       [0.24559275, 0.75440725],\n",
       "       [0.5662996 , 0.4337004 ],\n",
       "       [0.87737541, 0.12262459],\n",
       "       [0.29308287, 0.70691713],\n",
       "       [0.41634563, 0.58365437],\n",
       "       [0.72586122, 0.27413878],\n",
       "       [0.31683213, 0.68316787],\n",
       "       [0.82638206, 0.17361794],\n",
       "       [0.84738944, 0.15261056],\n",
       "       [0.77133106, 0.22866894],\n",
       "       [0.7300077 , 0.2699923 ],\n",
       "       [0.74708659, 0.25291341],\n",
       "       [0.14880137, 0.85119863],\n",
       "       [0.70306858, 0.29693142],\n",
       "       [0.23583473, 0.76416527],\n",
       "       [0.75414044, 0.24585956],\n",
       "       [0.7849557 , 0.2150443 ],\n",
       "       [0.37899345, 0.62100655],\n",
       "       [0.31683213, 0.68316787],\n",
       "       [0.3009509 , 0.6990491 ],\n",
       "       [0.25754083, 0.74245917],\n",
       "       [0.55349928, 0.44650072],\n",
       "       [0.52051622, 0.47948378],\n",
       "       [0.72120075, 0.27879925],\n",
       "       [0.14880137, 0.85119863],\n",
       "       [0.22409477, 0.77590523],\n",
       "       [0.85302259, 0.14697741],\n",
       "       [0.91714155, 0.08285845],\n",
       "       [0.09654353, 0.90345647],\n",
       "       [0.3277294 , 0.6722706 ],\n",
       "       [0.66009241, 0.33990759],\n",
       "       [0.47609389, 0.52390611],\n",
       "       [0.44001423, 0.55998577],\n",
       "       [0.20887576, 0.79112424],\n",
       "       [0.1783463 , 0.8216537 ],\n",
       "       [0.45533557, 0.54466443],\n",
       "       [0.6893534 , 0.3106466 ],\n",
       "       [0.73863728, 0.26136272],\n",
       "       [0.8399901 , 0.1600099 ],\n",
       "       [0.19001459, 0.80998541],\n",
       "       [0.54516654, 0.45483346],\n",
       "       [0.77903962, 0.22096038],\n",
       "       [0.65072406, 0.34927594],\n",
       "       [0.78656024, 0.21343976],\n",
       "       [0.88776978, 0.11223022],\n",
       "       [0.25780614, 0.74219386],\n",
       "       [0.69874615, 0.30125385],\n",
       "       [0.3864439 , 0.6135561 ],\n",
       "       [0.78656024, 0.21343976],\n",
       "       [0.70306858, 0.29693142],\n",
       "       [0.65072406, 0.34927594],\n",
       "       [0.73284787, 0.26715213],\n",
       "       [0.47609389, 0.52390611],\n",
       "       [0.53930442, 0.46069558],\n",
       "       [0.68979648, 0.31020352],\n",
       "       [0.75414044, 0.24585956],\n",
       "       [0.54254271, 0.45745729]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba = reg.predict_proba(x_test)\n",
    "predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are interested in the probability of excessive absenteeism \n",
    "\n",
    "### Therefore , we can simply slice out all the values from second column\n",
    "\n",
    "### This will give us the probability of excessive absenteeism \n",
    "\n",
    "### Select ONLY the probabilities referring to 1s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28778024, 0.41239991, 0.55662562, 0.22096038, 0.91541657,\n",
       "       0.66896629, 0.70207504, 0.87043779, 0.21692179, 0.25291341,\n",
       "       0.50485031, 0.77359703, 0.92969016, 0.26495948, 0.69466915,\n",
       "       0.44964119, 0.44972574, 0.46069558, 0.59882226, 0.94679318,\n",
       "       0.30125385, 0.22096038, 0.58365437, 0.58365437, 0.7587085 ,\n",
       "       0.25682913, 0.48934806, 0.14296697, 0.80065765, 0.22096038,\n",
       "       0.37028423, 0.68316787, 0.68825755, 0.52694241, 0.22096038,\n",
       "       0.53492642, 0.22453007, 0.74389237, 0.40329273, 0.60301627,\n",
       "       0.21343976, 0.45483346, 0.2403088 , 0.4388431 , 0.82622935,\n",
       "       0.57857132, 0.69461059, 0.28778024, 0.22209028, 0.2061074 ,\n",
       "       0.57577123, 0.36438663, 0.66896629, 0.27128561, 0.83334736,\n",
       "       0.43399232, 0.88600663, 0.23396355, 0.37170685, 0.38209505,\n",
       "       0.69796139, 0.65909803, 0.29392197, 0.79686146, 0.20956093,\n",
       "       0.2699923 , 0.10399887, 0.22453007, 0.73944244, 0.30081832,\n",
       "       0.22453007, 0.32688766, 0.90337554, 0.45745729, 0.59997247,\n",
       "       0.22096038, 0.77863015, 0.72858977, 0.74344554, 0.67044828,\n",
       "       0.24847708, 0.08983463, 0.23396355, 0.75440725, 0.4337004 ,\n",
       "       0.12262459, 0.70691713, 0.58365437, 0.27413878, 0.68316787,\n",
       "       0.17361794, 0.15261056, 0.22866894, 0.2699923 , 0.25291341,\n",
       "       0.85119863, 0.29693142, 0.76416527, 0.24585956, 0.2150443 ,\n",
       "       0.62100655, 0.68316787, 0.6990491 , 0.74245917, 0.44650072,\n",
       "       0.47948378, 0.27879925, 0.85119863, 0.77590523, 0.14697741,\n",
       "       0.08285845, 0.90345647, 0.6722706 , 0.33990759, 0.52390611,\n",
       "       0.55998577, 0.79112424, 0.8216537 , 0.54466443, 0.3106466 ,\n",
       "       0.26136272, 0.1600099 , 0.80998541, 0.45483346, 0.22096038,\n",
       "       0.34927594, 0.21343976, 0.11223022, 0.74219386, 0.30125385,\n",
       "       0.6135561 , 0.21343976, 0.29693142, 0.34927594, 0.26715213,\n",
       "       0.52390611, 0.46069558, 0.31020352, 0.24585956, 0.45745729])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model \n",
    "\n",
    "### Saving a model is the process of creating a file that will contain all the information regarding the machine learning.\n",
    "\n",
    "### Roughly speaking we want to create a file that will store the following information\n",
    "\n",
    "### This machine learning model is a logistic regression \n",
    "\n",
    "### So , it store coefficient and intercept and the random state choosen for shuffling is 20 \n",
    "\n",
    "### The object reg which is the instance of the Sklearn logistic class contains all this information \n",
    "\n",
    "### Infact this is the object we use to find the intercept , coefficient and accuracy\n",
    "\n",
    "### Saving the model is equivalent to saving the 'reg' object \n",
    "\n",
    "### Using the pyhton pickle module \n",
    "\n",
    "### Pickling is the process of converting a python object into a chracter stream\n",
    "\n",
    "### The main idea is that this character stream will contain sufficient information\n",
    "\n",
    "### Then later when we would like to convert the character stream into python object in another notebook we will unpickle it\n",
    "\n",
    "\n",
    "### In plain in english it means we will save the reg variable into file , This file will then loaded into the new notebook and thus able to use the machine learning algorithm  \n",
    "\n",
    "\n",
    "### The file size will be (only character , so) less than 1KB , so we can send it by email or even facebook and our colleagues will unpickle it and use in their code \n",
    "\n",
    "\n",
    "### Import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model','wb') as file:\n",
    "    pickle.dump(reg,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
